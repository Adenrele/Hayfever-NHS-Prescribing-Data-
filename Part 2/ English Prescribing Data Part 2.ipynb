{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHSBSA English Prescribing Data (EPD) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: SQL, AWS EC2 Instance and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 26 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   BNF_CODE                      5 non-null      object \n",
      " 1   TOTAL_QUANTITY                5 non-null      float64\n",
      " 2   POSTCODE                      5 non-null      object \n",
      " 3   YEAR_MONTH                    5 non-null      int64  \n",
      " 4   UNIDENTIFIED                  5 non-null      bool   \n",
      " 5   PRACTICE_NAME                 5 non-null      object \n",
      " 6   BNF_CHAPTER_PLUS_CODE         5 non-null      object \n",
      " 7   ACTUAL_COST                   5 non-null      float64\n",
      " 8   QUANTITY                      5 non-null      float64\n",
      " 9   REGIONAL_OFFICE_CODE          5 non-null      object \n",
      " 10  ITEMS                         5 non-null      int64  \n",
      " 11  ADDRESS_4                     5 non-null      object \n",
      " 12  AREA_TEAM_CODE                5 non-null      object \n",
      " 13  ADDRESS_2                     5 non-null      object \n",
      " 14  ADDRESS_3                     5 non-null      object \n",
      " 15  BNF_CHEMICAL_SUBSTANCE        5 non-null      object \n",
      " 16  ADQUSAGE                      5 non-null      float64\n",
      " 17  PCO_CODE                      5 non-null      object \n",
      " 18  REGIONAL_OFFICE_NAME          5 non-null      object \n",
      " 19  NIC                           5 non-null      float64\n",
      " 20  CHEMICAL_SUBSTANCE_BNF_DESCR  5 non-null      object \n",
      " 21  PRACTICE_CODE                 5 non-null      object \n",
      " 22  PCO_NAME                      5 non-null      object \n",
      " 23  AREA_TEAM_NAME                5 non-null      object \n",
      " 24  BNF_DESCRIPTION               5 non-null      object \n",
      " 25  ADDRESS_1                     5 non-null      object \n",
      "dtypes: bool(1), float64(5), int64(2), object(18)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "url = \"https://opendata.nhsbsa.net/api/3/action/datastore_search_sql?resource_id=EPD_201401&sql=SELECT * from `EPD_201401` limit 5\"\n",
    "pd.DataFrame(requests.get(url).json()['result']['result']['records']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the SQL query\n",
    "\n",
    "years = [19,20,21]\n",
    "months = list(range(13))[1:]\n",
    "resources = []\n",
    "for year in years:\n",
    "    resource_name_year = \"EPD_20\"+str(year)\n",
    "    for month in months:\n",
    "        resource_names = resource_name_year+str(month).zfill(2)\n",
    "        resources.append(resource_names)\n",
    "\n",
    "        \n",
    "EPDs_needed = resources[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the url for the API call\n",
    "base_endpoint = \"https://opendata.nhsbsa.net/api/3/action\"\n",
    "action_method = \"/datastore_search_sql?\" # SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe filters used in the Pandas dataframe within part 1 will inform the SQL API query.\\n\\nCHEMICAL_SUBSTANCE_BNF_DESCR = 'Cetirizine hydrochloride'                           \\nCHEMICAL_SUBSTANCE_BNF_DESCR = 'Loratadine'                                       \\nCHEMICAL_SUBSTANCE_BNF_DESCR = 'Desloratadine'                                        \\nCHEMICAL_SUBSTANCE_BNF_DESCR = 'Fexofenadine hydrochloride'\\nCHEMICAL_SUBSTANCE_BNF_DESCR = 'Acrivastine'                                           \\nCHEMICAL_SUBSTANCE_BNF_DESCR ='Bilastine'                                             \\nCHEMICAL_SUBSTANCE_BNF_DESCR ='Levocetirizine'                               \\nCHEMICAL_SUBSTANCE_BNF_DESCR ='Mizolastine'                                   \\nCHEMICAL_SUBSTANCE_BNF_DESCR ='Chlorphenamine maleate'                               \\nBNF_DESCRIPTION != 'Chlorphenamine 10mg/1ml solution for injection ampoules'            \\nCHEMICAL_SUBSTANCE_BNF_DESCR='Promethazine hydrochloride'\\nBNF_DESCRIPTION != 'Promethazine 25mg/1ml solution for injection ampoules'             \\nBNF_DESCRIPTION !='Phenergan 25mg/1ml solution for injection ampoules'                \\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The filters used in the Pandas dataframe within part 1 will inform the SQL API query.\n",
    "\n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR = 'Cetirizine hydrochloride'                           \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR = 'Loratadine'                                       \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR = 'Desloratadine'                                        \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR = 'Fexofenadine hydrochloride'\n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR = 'Acrivastine'                                           \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR ='Bilastine'                                             \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR ='Levocetirizine'                               \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR ='Mizolastine'                                   \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR ='Chlorphenamine maleate'                               \n",
    "BNF_DESCRIPTION != 'Chlorphenamine 10mg/1ml solution for injection ampoules'            \n",
    "CHEMICAL_SUBSTANCE_BNF_DESCR='Promethazine hydrochloride'\n",
    "BNF_DESCRIPTION != 'Promethazine 25mg/1ml solution for injection ampoules'             \n",
    "BNF_DESCRIPTION !='Phenergan 25mg/1ml solution for injection ampoules'                \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_name = \"EPD_202002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT \n",
    "    \n",
    "    TOTAL_QUANTITY, \n",
    "    POSTCODE, \n",
    "    YEAR_MONTH,\n",
    "    PRACTICE_NAME,\n",
    "    ACTUAL_COST,\n",
    "    BNF_CHEMICAL_SUBSTANCE,\n",
    "    REGIONAL_OFFICE_NAME,\n",
    "    CHEMICAL_SUBSTANCE_BNF_DESCR,\n",
    "    AREA_TEAM_NAME\n",
    "    \n",
    "    FROM \n",
    "        `{resource_name}`     \n",
    "    WHERE\n",
    "    1=1\n",
    "    AND CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Cetirizine hydrochloride'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Loratadine'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Fexofenadine hydrochloride'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Acrivastine'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Bilastine'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Levocetirizine'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Mizolastine'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Chlorphenamine maleate'}'\n",
    "        OR CHEMICAL_SUBSTANCE_BNF_DESCR = '{'Promethazine hydrochloride'}'\n",
    "       \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send API call and grab the response as a json\n",
    "response = requests.get(\n",
    "    url=(\n",
    "        base_endpoint \n",
    "        + action_method \n",
    "        + \"resource_id=\" + resource_name\n",
    "        + \"&\"\n",
    "        + \"sql=\" + requests.utils.quote(query) # Encode url\n",
    "    ),\n",
    "    verify=False\n",
    ").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['help', 'success', 'result'])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'records_truncated': 'true',\n",
       " 'gc_urls': [{'url': 'https://storage.googleapis.com/dx-nhs-tmp/anon0737d9acc1e411ef08afe0463c17a975734863ef/`EPD_202002`-000000000000.csv.gz'}],\n",
       " 'help': 'https://demo.ckan.org/api/3/action/help_show?name=datastore_search_sql',\n",
       " 'success': 'true'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Met_Pollen_Data = ['PollenStationData2011.xlsx',\n",
    "                   'PollenStationData2012.xlsx', \n",
    "                   'PollenStationData2013.xlsx', \n",
    "                   'PollenStationData2014.xlsx', \n",
    "                   'PollenStationData2015.xlsx', \n",
    "                   'PollenStationData2016.xlsx',\n",
    "                   'PollenStationData2017.xlsx', \n",
    "                   'PollenStationData2018.xlsx', \n",
    "                   'PollenStationData2019.xlsx',\n",
    "                   'PollenStationData2020.xlsx', \n",
    "                   'PollenStationData2021vs30June.xlsx']\n",
    "\n",
    "sheets_required = ['Bath',\n",
    "                   'Belfast',\n",
    "                   'Cambridge',\n",
    "                   'Cardiff',\n",
    "                   'East Riding',\n",
    "                   'Edinburgh',\n",
    "                   'Eskdalemuir',\n",
    "                   'Exeter',\n",
    "                   'Hull',\n",
    "                   'Invergowrie',\n",
    "                   'Ipswich',\n",
    "                   'Isle of Wight',\n",
    "                   'Leicester',\n",
    "                   'London, Islington',\n",
    "                   'London, Kings College',\n",
    "                   'Plymouth',\n",
    "                   'Rotherham',\n",
    "                   'Worcester',\n",
    "                   'York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cory</th>\n",
       "      <th>Alnu</th>\n",
       "      <th>Sali</th>\n",
       "      <th>Betu</th>\n",
       "      <th>Frax</th>\n",
       "      <th>Ulmu</th>\n",
       "      <th>Quer</th>\n",
       "      <th>Plat</th>\n",
       "      <th>Poac</th>\n",
       "      <th>Urti</th>\n",
       "      <th>Arte</th>\n",
       "      <th>Ambr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Bath</th>\n",
       "      <th>0</th>\n",
       "      <td>2011-05-16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-05-17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-18</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-05-19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-05-20</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Cory  Alnu  Sali  Betu  Frax  Ulmu  Quer  Plat  Poac  Urti  \\\n",
       "Bath 0 2011-05-16   -1  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "     1 2011-05-17   -1  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   0.0  -1.0   \n",
       "     2 2011-05-18   -1  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "     3 2011-05-19   -1  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   7.0  -1.0   \n",
       "     4 2011-05-20   -1  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   4.0  -1.0   \n",
       "\n",
       "        Arte  Ambr  \n",
       "Bath 0  -1.0  -1.0  \n",
       "     1  -1.0  -1.0  \n",
       "     2  -1.0  -1.0  \n",
       "     3  -1.0  -1.0  \n",
       "     4  -1.0  -1.0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('PollenStationData2011.xlsx', sheet_name =sheets_required)\n",
    "df_new = pd.concat(df)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/15159253/python-try-except-block-does-not-recognize-error-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pollen_types_ = {'Cory':'Hazel Pollen',\n",
    "                'Alnu': 'Alder Pollen',\n",
    "                'Sali':'Willow Pollen',\n",
    "                'Betu': 'Birch Pollen',\n",
    "                'Frax': 'Ash Pollen',\n",
    "                'Ulmu':'Elm Pollen',\n",
    "                'Quer':'Oak Pollen',\n",
    "                'Plat':'Plane (tree) Pollen',\n",
    "                'Poac':'Grass Pollen',\n",
    "                'Urti':'Nettle Pollen',\n",
    "                'Arte':'Mugwort Pollen',\n",
    "                'Ambr': 'Ragweed Pollen'}\n",
    "\n",
    "\n",
    "from xlrd import XLRDError\n",
    "\n",
    "dfs=[]\n",
    "\n",
    "\n",
    "for pollen_data in Met_Pollen_Data:\n",
    "    try:\n",
    "        df = pd.read_excel(pollen_data, sheet_name =sheets_required)\n",
    "    \n",
    "    except XLRDError:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    for location in list(df.keys()):\n",
    "            df[location]['Location']= location\n",
    "                    \n",
    "    df_new = pd.concat(df)\n",
    "    \n",
    "    df_new.reset_index(drop=True, inplace = True)\n",
    "    \n",
    "    dfs.append(df_new)\n",
    "    met_pollen_df =pd.concat(dfs)\n",
    "\n",
    "met_pollen_df.rename(mapper=Pollen_types, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26664 entries, 0 to 2423\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Date                 26664 non-null  datetime64[ns]\n",
      " 1   Hazel Pollen         25773 non-null  object        \n",
      " 2   Alder Pollen         25729 non-null  float64       \n",
      " 3   Willow Pollen        25729 non-null  float64       \n",
      " 4   Birch Pollen         25729 non-null  float64       \n",
      " 5   Ash Pollen           25729 non-null  float64       \n",
      " 6   Elm Pollen           25729 non-null  float64       \n",
      " 7   Oak Pollen           25729 non-null  float64       \n",
      " 8   Plame (tree) Pollen  25729 non-null  float64       \n",
      " 9   Grass Pollen         25729 non-null  float64       \n",
      " 10  Nettle Pollen        25729 non-null  float64       \n",
      " 11  Mugwort Pollen       25729 non-null  float64       \n",
      " 12  Ragweed Pollen       25729 non-null  float64       \n",
      " 13  Location             26664 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(11), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "met_pollen_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Cloud Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPD_Server = xmlrpc.client.ServerProxy('http://54.196.229.110:2021')\n",
    "df = EPD_Server.LargeCSVsChop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_2020_df = LargeCSVsChop(datasets[72:73])\n",
    "Feb_2020_df = LargeCSVsChop(datasets[73:74])\n",
    "Mar_2020_df = LargeCSVsChop(datasets[74:75])\n",
    "Apr_2020_df = LargeCSVsChop(datasets[75:76])\n",
    "May_2020_df = LargeCSVsChop(datasets[76:77])\n",
    "Jun_2020_df = LargeCSVsChop(datasets[77:78])\n",
    "Jul_2020_df = LargeCSVsChop(datasets[78:79])\n",
    "Aug_2020_df = LargeCSVsChop(datasets[79:80])\n",
    "Sep_2020_df = LargeCSVsChop(datasets[80:81])\n",
    "Oct_2020_df = LargeCSVsChop(datasets[81:82])\n",
    "Nov_2020_df = LargeCSVsChop(datasets[82:83])\n",
    "Dec_2020_df = LargeCSVsChop(datasets[83:84])\n",
    "\n",
    "HayFev_df_2020_list = [Jan_2020_df,Feb_2020_df ,Mar_2020_df,Apr_2020_df,May_2020_df,Jun_2020_df,Jul_2020_df,\n",
    "                       Aug_2020_df,Sep_2020_df,Oct_2020_df,Nov_2020_df,Dec_2020_df ]\n",
    "\n",
    "HayFev_df_2020 = pd.concat(HayFev_df_2020_list)\n",
    "\n",
    "HayFev_df_2020.to_csv('HayFev_df_2020.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the cost of hardware, I am more inclined to look for workarounds such as these to facilitate and speed up personal projects. I hope this has been useful to others and I would love comments and feedback on my code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole year of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each csv is read in individual lines as opposed to one to allow for fleixibility when the kernel needs to be interrupted due to the time taken or any other issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feb_2019_df = LargeCSVsChop(datasets[61:62])\n",
    "Mar_2019_df = LargeCSVsChop(datasets[62:63])\n",
    "Apr_2019_df = LargeCSVsChop(datasets[63:64])\n",
    "May_2019_df = LargeCSVsChop(datasets[64:65])\n",
    "Jun_2019_df = LargeCSVsChop(datasets[65:66])\n",
    "Jul_2019_df = LargeCSVsChop(datasets[66:67])\n",
    "Aug_2019_df = LargeCSVsChop(datasets[67:68])\n",
    "Sep_2019_df = LargeCSVsChop(datasets[68:69])\n",
    "Oct_2019_df = LargeCSVsChop(datasets[69:70])\n",
    "Nov_2019_df = LargeCSVsChop(datasets[70:71])\n",
    "Dec_2019_df = LargeCSVsChop(datasets[71:72])\n",
    "\n",
    "HayFev_df_2019_list = [Jan_2019_df,Feb_2019_df ,Mar_2019_df,Apr_2019_df,May_2019_df,Jun_2019_df,Jul_2019_df,\n",
    "                       Aug_2019_df,Sep_2019_df,Oct_2019_df,Nov_2019_df,Dec_2019_df ]\n",
    "\n",
    "HayFev_df_2019 = pd.concat(HayFev_df_2019_list)\n",
    "\n",
    "HayFev_df_2019.to_csv('HayFev_df_2019.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
